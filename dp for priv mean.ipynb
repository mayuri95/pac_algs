{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75abefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algs_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bcd95edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_to_threshold(vec, c):\n",
    "    curr_norm = np.linalg.norm(vec)\n",
    "    if curr_norm <= c:\n",
    "        return vec\n",
    "    clip_ratio = c / curr_norm\n",
    "    return [vec[i]*clip_ratio for i in range(len(vec))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82529d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(scale):\n",
    "    return np.random.laplace(scale)\n",
    "# global sensitivity is C/n i think?\n",
    "# so scale should be (C/n) / \\epsilon per elem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94210938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_posterior(mi, prior=0.5, prec = 100000):\n",
    "    test_vals = [x / prec for x in range(1, prec)]\n",
    "    max_t = None\n",
    "    for t in test_vals:\n",
    "        if t*np.log(t/prior)+(1-t)*np.log((1-t)/(1-prior)) <= mi:\n",
    "            if  max_t is None or t > max_t:\n",
    "                max_t = t\n",
    "    return max_t\n",
    "\n",
    "def dp_epsilon_to_posterior_success(epsilon):\n",
    "    return 1 - 1./(1+np.exp(epsilon))\n",
    "\n",
    "def dp_ps_to_epsilon(ps):\n",
    "    return np.log(ps / (1-ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f9873d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_noise_auto(train_x, train_y, subsample_rate, num_classes,\n",
    "    eta, regularize=None, num_trees=None, tree_depth = None, max_mi = 0.5, num_dims = None):\n",
    "\n",
    "    sec_v = max_mi / 2\n",
    "    sec_beta = max_mi - sec_v\n",
    "    r = calc_r(train_x)\n",
    "    gamma = 0.01\n",
    "    avg_dist = 0.\n",
    "    curr_est = None\n",
    "    converged = False\n",
    "    curr_trial = 0\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = len(set(train_y))\n",
    "\n",
    "    assert subsample_rate >= num_classes\n",
    "\n",
    "    est_y = {}\n",
    "    prev_ests = None\n",
    "    # 10*c*v\n",
    "    seed = np.random.randint(1, 100000)\n",
    "\n",
    "    s1 = None # only relevant for PCA\n",
    "    \n",
    "    while not converged:\n",
    "        shuffled_x, shuffled_y = shuffle(train_x, train_y)\n",
    "        \n",
    "        shuffled_x, shuffled_y = get_samples_safe(shuffled_x, shuffled_y, num_classes, subsample_rate)\n",
    "        \n",
    "        output = np.average(shuffled_x, axis=0)\n",
    "\n",
    "        for ind in range(len(output)):\n",
    "            if ind not in est_y:\n",
    "                est_y[ind] = []\n",
    "            est_y[ind].append(output[ind])\n",
    "\n",
    "        if curr_trial % 10 == 0:        \n",
    "            if prev_ests is None:\n",
    "                prev_ests = {}\n",
    "                for ind in est_y:\n",
    "                    prev_ests[ind] = np.var(est_y[ind])\n",
    "            else:\n",
    "                converged = True\n",
    "                for ind in est_y:\n",
    "                    if abs(np.var(est_y[ind]) - prev_ests[ind]) > eta:\n",
    "                        converged = False\n",
    "                if not converged:\n",
    "                    for ind in est_y:\n",
    "                        prev_ests[ind] = np.var(est_y[ind])\n",
    "        curr_trial += 1\n",
    "    fin_var = {ind: np.var(est_y[ind]) for ind in est_y}\n",
    "\n",
    "    noise = {}\n",
    "    sqrt_total_var = sum([fin_var[x]**0.5 for x in fin_var])\n",
    "    for ind in fin_var:\n",
    "        noise[ind] = 1./(2*max_mi) * fin_var[ind]**0.5 * sqrt_total_var\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b3e34fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_iris()\n",
    "\n",
    "norms = [np.linalg.norm(x) for x in train_x]\n",
    "# print(max(norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "42e5d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.51291546492478, 1.6426117097961406, 0.7304317044395013, 0.3563228120191924]\n",
      "[0.99999, 0.83789, 0.6749, 0.58815]\n"
     ]
    }
   ],
   "source": [
    "true_mean = np.average(train_x, axis=0)\n",
    "\n",
    "mi_range = [1.0, 0.25, 0.0625, 0.015625]\n",
    "posterior_success_rates = [calc_posterior(mi) for mi in mi_range]\n",
    "epsilon_vals = [dp_ps_to_epsilon(ps) for ps in posterior_success_rates]\n",
    "\n",
    "print(epsilon_vals)\n",
    "print([x for x in posterior_success_rates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a638ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP MEAN\n",
    "dp_dists = {}\n",
    "num_trials = 1000\n",
    "\n",
    "for eps in epsilon_vals:\n",
    "    avg_dist_dp = {}\n",
    "    for i in range(1, 220):\n",
    "        clip_budget = i / 20. # 0.05 \n",
    "        clipped_train_x = [clip_to_threshold(train_x[i], clip_budget) for i in range(len(train_x))]\n",
    "        released_mean = np.average(clipped_train_x, axis=0)\n",
    "        clip_dist = np.linalg.norm(released_mean - true_mean)\n",
    "        dist = 0.\n",
    "        for _ in range(num_trials):\n",
    "            released_mean = np.average(clipped_train_x, axis=0)\n",
    "            for ind in range(len(released_mean)):\n",
    "                sensitivity = clip_budget / train_len \n",
    "                released_mean[ind] += add_noise(sensitivity / eps)\n",
    "            dist += np.linalg.norm(released_mean - true_mean)\n",
    "        dist /= num_trials\n",
    "        avg_dist_dp[i] = (clip_dist, dist)\n",
    "    dp_key = min(avg_dist_dp.items(), key=lambda x: x[1][1])[0]\n",
    "    dp_dists[eps] = avg_dist_dp[dp_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1de7c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11.51291546492478: (0.005589453936607491, 2.414644707168465),\n",
       " 1.6426117097961406: (0.08284865477957871, 2.404570812928289),\n",
       " 0.7304317044395013: (0.0, 2.4319473328763332),\n",
       " 0.3563228120191924: (0.3379551420939025, 2.4432985634448583)}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1429e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAC MEAN\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "noise = hybrid_noise_auto(train_x, train_y, subsample_rate, num_classes, 1e-6)\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "    subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d93b3336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.028578130875505172,\n",
       " 1: 0.016058658559470425,\n",
       " 2: 0.06149385186092042,\n",
       " 3: 0.027026669637757513}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "050b6792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7004608294930876"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.69/2.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "559fd53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_bean(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d933e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.033332638023896\n"
     ]
    }
   ],
   "source": [
    "true_mean = np.average(train_x, axis=0)\n",
    "\n",
    "norms = [np.linalg.norm(x) for x in train_x]\n",
    "print(max(norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cb0127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13949812, 0.22676071, 0.24652181, 0.23625196, 0.39830925,\n",
       "       0.76938283, 0.1365661 , 0.22534371, 0.62571808, 0.89973101,\n",
       "       0.76502333, 0.45814466, 0.49316895, 0.36997741, 0.41194519,\n",
       "       0.9095871 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cc5c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP MEAN\n",
    "dp_dists = {}\n",
    "num_trials = 1000\n",
    "\n",
    "for eps in epsilon_vals:\n",
    "    avg_dist_dp = {}\n",
    "    for i in range(1, 62):\n",
    "        clip_budget = i / 20.\n",
    "        clipped_train_x = [clip_to_threshold(train_x[i], clip_budget) for i in range(len(train_x))]\n",
    "        released_mean = np.average(clipped_train_x, axis=0)\n",
    "        clip_dist = np.linalg.norm(released_mean - true_mean)\n",
    "        dist = 0.\n",
    "        for _ in range(num_trials):\n",
    "            released_mean = np.average(clipped_train_x, axis=0)\n",
    "            for ind in range(len(released_mean)):\n",
    "                sensitivity = clip_budget / train_len \n",
    "                released_mean[ind] += add_noise(sensitivity / eps)\n",
    "            dist += np.linalg.norm(released_mean - true_mean)\n",
    "        dist /= num_trials\n",
    "        avg_dist_dp[i] = (clip_dist, dist)\n",
    "    dp_key = min(avg_dist_dp.items(), key=lambda x: x[1][1])[0]\n",
    "    dp_dists[eps] = avg_dist_dp[dp_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9188f447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11.51291546492478: (0.00011472786248996413, 5.397195637416383),\n",
       " 1.6426117097961406: (0.022664005320329528, 5.396575923514626),\n",
       " 0.7304317044395013: (0.40049136963183046, 5.364796508769275),\n",
       " 0.3563228120191924: (0.44875470877922397, 5.358119756917312)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbd34b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAC MEAN\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "noise = hybrid_noise_auto(train_x, train_y, subsample_rate, num_classes, 1e-6)\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "    subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab9f416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: (0.005402634291839429, 0.005402545268518531, 0.0053194949322241175),\n",
       " 0.25: (0.005319329253503482, 0.0053230113150411155, 0.005361969629488425),\n",
       " 0.0625: (0.005355829056043277, 0.005413356185585519, 0.005501557336572924),\n",
       " 0.015625: (0.005408692491632391, 0.006300209931213997, 0.006706026642238748)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f95fbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7351afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_rice(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "963bb53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3296929410457268\n"
     ]
    }
   ],
   "source": [
    "true_mean = np.average(train_x, axis=0)\n",
    "\n",
    "norms = [np.linalg.norm(x) for x in train_x]\n",
    "print(max(norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "914db068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44882084, 0.50127565, 0.46280648, 0.55699467, 0.64165913,\n",
       "       0.45820917, 0.454011  ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d11e9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP MEAN\n",
    "dp_dists = {}\n",
    "num_trials = 1000\n",
    "\n",
    "for eps in epsilon_vals:\n",
    "    avg_dist_dp = {}\n",
    "    for i in range(1, 48):\n",
    "        clip_budget = i / 20.\n",
    "        clipped_train_x = [clip_to_threshold(train_x[i], clip_budget) for i in range(len(train_x))]\n",
    "        released_mean = np.average(clipped_train_x, axis=0)\n",
    "        clip_dist = np.linalg.norm(released_mean - true_mean)\n",
    "        dist = 0.\n",
    "        for _ in range(num_trials):\n",
    "            released_mean = np.average(clipped_train_x, axis=0)\n",
    "            for ind in range(len(released_mean)):\n",
    "                sensitivity = clip_budget / train_len \n",
    "                released_mean[ind] += add_noise(sensitivity / eps)\n",
    "            dist += np.linalg.norm(released_mean - true_mean)\n",
    "        dist /= num_trials\n",
    "        avg_dist_dp[i] = (clip_dist, dist)\n",
    "    dp_key = min(avg_dist_dp.items(), key=lambda x: x[1][1])[0]\n",
    "    dp_dists[eps] = avg_dist_dp[dp_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f84fb3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11.51291546492478: (0.3776770756195068, 3.3823852954087963),\n",
       " 1.6426117097961406: (0.2194404456981254, 3.3524872064037132),\n",
       " 0.7304317044395013: (0.29280740534432015, 3.3836859246706905),\n",
       " 0.3563228120191924: (0.11230215784580518, 3.3981163471357414)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7e8af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAC MEAN\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "noise = hybrid_noise_auto(train_x, train_y, subsample_rate, num_classes, 1e-6)\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "    subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c73c4799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: (0.007543825045711737, 0.007543184221990362, 0.007572223452566617),\n",
       " 0.25: (0.00763998912500602, 0.007645582684431556, 0.007631803548210275),\n",
       " 0.0625: (0.00746459681578852, 0.007598925465874449, 0.007985333967967552),\n",
       " 0.015625: (0.007352115992608959, 0.009083210939745826, 0.010733538914307353)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e8bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b836088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
