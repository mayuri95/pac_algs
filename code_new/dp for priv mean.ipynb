{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "75abefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algs_lib import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "bcd95edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_to_threshold(vec, c):\n",
    "    curr_norm = np.linalg.norm(vec)\n",
    "#     print(curr_norm, c)\n",
    "    if curr_norm <= c:\n",
    "        return vec\n",
    "#     print('reached')\n",
    "    clip_ratio = c / curr_norm\n",
    "    return [vec[i]*clip_ratio for i in range(len(vec))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "82529d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(scale):\n",
    "    return np.random.laplace(0, scale)\n",
    "# global sensitivity is C/n i think?\n",
    "# so scale should be (C/n) / \\epsilon per elem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "94210938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_posterior(mi, prior=0.5, prec = 100000):\n",
    "    test_vals = [x / prec for x in range(1, prec)]\n",
    "    max_t = None\n",
    "    for t in test_vals:\n",
    "        if t*np.log(t/prior)+(1-t)*np.log((1-t)/(1-prior)) <= mi:\n",
    "            if  max_t is None or t > max_t:\n",
    "                max_t = t\n",
    "    return max_t\n",
    "\n",
    "def dp_epsilon_to_posterior_success(epsilon):\n",
    "    return 1 - 1./(1+np.exp(epsilon))\n",
    "\n",
    "def dp_ps_to_epsilon(ps):\n",
    "    return np.log(ps / (1-ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ea8b3307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03213"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_posterior(1./64, prior=0.01)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b7370f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_iris(normalize=True)\n",
    "subsample_rate = int(0.5*train_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9a1ea429",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "est_y = {}\n",
    "est_x = {}\n",
    "prev_ests = None\n",
    "seed = 743895091 # randomly generated seed for reproducibility\n",
    "num_trials = 1024\n",
    "curr_trial = 0\n",
    "max_noises = {}\n",
    "\n",
    "while curr_trial < num_trials:\n",
    "    shuffled_inds = shuffle(list(range(len(train_x))))\n",
    "    # shuffled_x, shuffled_y = shuffle(train_x, train_y)\n",
    "    x, y = train_x[shuffled_inds], train_y[shuffled_inds]\n",
    "    x1, y1 = x[:subsample_rate], y[:subsample_rate]\n",
    "    x2, y2 = x[subsample_rate:], y[subsample_rate:]\n",
    "    inds_1, inds_2 = shuffled_inds[:subsample_rate], shuffled_inds[subsample_rate:]\n",
    "    est_x[curr_trial] = inds_1\n",
    "    est_x[curr_trial + 1] = inds_2\n",
    "    curr_trial += 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6756f77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(est_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "db24df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = 0\n",
    "\n",
    "xs_in = [k for k in est_x if ind in est_x[k]]\n",
    "xs_out = [k for k in est_x if ind not in est_x[k]]\n",
    "\n",
    "for set_ind in xs_in:\n",
    "    s_x = set(est_x[set_ind])\n",
    "\n",
    "    best_match, best_overlap = None, None\n",
    "    for k in xs_out:\n",
    "        indices = est_x[k]\n",
    "        overlap = len(set(indices).intersection(s_x))\n",
    "        if best_overlap is None or overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            best_match = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b78059b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs_in), len(xs_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "415288ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 13,\n",
       " 14,\n",
       " 17,\n",
       " 18,\n",
       " 21,\n",
       " 23,\n",
       " 24,\n",
       " 27,\n",
       " 29,\n",
       " 30,\n",
       " 32,\n",
       " 35,\n",
       " 36,\n",
       " 38,\n",
       " 40,\n",
       " 42,\n",
       " 45,\n",
       " 47,\n",
       " 49,\n",
       " 50,\n",
       " 52,\n",
       " 55,\n",
       " 57,\n",
       " 59,\n",
       " 61,\n",
       " 62,\n",
       " 65,\n",
       " 67,\n",
       " 68,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 76,\n",
       " 79,\n",
       " 81,\n",
       " 82,\n",
       " 84,\n",
       " 87,\n",
       " 89,\n",
       " 91,\n",
       " 93,\n",
       " 94,\n",
       " 97,\n",
       " 99,\n",
       " 100,\n",
       " 102,\n",
       " 105,\n",
       " 106,\n",
       " 108,\n",
       " 110,\n",
       " 113,\n",
       " 115,\n",
       " 116,\n",
       " 119,\n",
       " 120,\n",
       " 123,\n",
       " 124,\n",
       " 127,\n",
       " 128,\n",
       " 130,\n",
       " 133,\n",
       " 134,\n",
       " 136,\n",
       " 139,\n",
       " 140,\n",
       " 143,\n",
       " 144,\n",
       " 147,\n",
       " 148,\n",
       " 151,\n",
       " 152,\n",
       " 154,\n",
       " 156,\n",
       " 159,\n",
       " 161,\n",
       " 163,\n",
       " 165,\n",
       " 167,\n",
       " 168,\n",
       " 170,\n",
       " 173,\n",
       " 174,\n",
       " 177,\n",
       " 178,\n",
       " 180,\n",
       " 182,\n",
       " 184,\n",
       " 187,\n",
       " 188,\n",
       " 190,\n",
       " 193,\n",
       " 195,\n",
       " 197,\n",
       " 198,\n",
       " 200,\n",
       " 203,\n",
       " 205,\n",
       " 207,\n",
       " 209,\n",
       " 210,\n",
       " 213,\n",
       " 215,\n",
       " 216,\n",
       " 219,\n",
       " 221,\n",
       " 223,\n",
       " 225,\n",
       " 226,\n",
       " 229,\n",
       " 231,\n",
       " 232,\n",
       " 234,\n",
       " 236,\n",
       " 239,\n",
       " 240,\n",
       " 243,\n",
       " 245,\n",
       " 246,\n",
       " 248,\n",
       " 250,\n",
       " 253,\n",
       " 254,\n",
       " 256,\n",
       " 259,\n",
       " 260,\n",
       " 262,\n",
       " 264,\n",
       " 267,\n",
       " 268,\n",
       " 271,\n",
       " 273,\n",
       " 274,\n",
       " 276,\n",
       " 278,\n",
       " 280,\n",
       " 283,\n",
       " 285,\n",
       " 286,\n",
       " 288,\n",
       " 291,\n",
       " 292,\n",
       " 295,\n",
       " 297,\n",
       " 299,\n",
       " 300,\n",
       " 303,\n",
       " 305,\n",
       " 307,\n",
       " 308,\n",
       " 311,\n",
       " 312,\n",
       " 315,\n",
       " 317,\n",
       " 319,\n",
       " 320,\n",
       " 323,\n",
       " 324,\n",
       " 326,\n",
       " 328,\n",
       " 331,\n",
       " 332,\n",
       " 335,\n",
       " 336,\n",
       " 339,\n",
       " 340,\n",
       " 342,\n",
       " 345,\n",
       " 346,\n",
       " 349,\n",
       " 351,\n",
       " 352,\n",
       " 354,\n",
       " 357,\n",
       " 359,\n",
       " 361,\n",
       " 362,\n",
       " 365,\n",
       " 366,\n",
       " 369,\n",
       " 371,\n",
       " 372,\n",
       " 374,\n",
       " 377,\n",
       " 378,\n",
       " 380,\n",
       " 382,\n",
       " 384,\n",
       " 386,\n",
       " 389,\n",
       " 390,\n",
       " 393,\n",
       " 394,\n",
       " 397,\n",
       " 398,\n",
       " 400,\n",
       " 402,\n",
       " 404,\n",
       " 407,\n",
       " 408,\n",
       " 410,\n",
       " 413,\n",
       " 415,\n",
       " 417,\n",
       " 418,\n",
       " 420,\n",
       " 423,\n",
       " 425,\n",
       " 427,\n",
       " 428,\n",
       " 431,\n",
       " 432,\n",
       " 435,\n",
       " 436,\n",
       " 439,\n",
       " 440,\n",
       " 442,\n",
       " 445,\n",
       " 447,\n",
       " 449,\n",
       " 451,\n",
       " 452,\n",
       " 454,\n",
       " 456,\n",
       " 458,\n",
       " 460,\n",
       " 463,\n",
       " 465,\n",
       " 466,\n",
       " 469,\n",
       " 470,\n",
       " 472,\n",
       " 474,\n",
       " 477,\n",
       " 478,\n",
       " 481,\n",
       " 483,\n",
       " 484,\n",
       " 487,\n",
       " 489,\n",
       " 490,\n",
       " 493,\n",
       " 495,\n",
       " 497,\n",
       " 498,\n",
       " 500,\n",
       " 503,\n",
       " 505,\n",
       " 507,\n",
       " 509,\n",
       " 510,\n",
       " 512,\n",
       " 514,\n",
       " 516,\n",
       " 518,\n",
       " 520,\n",
       " 523,\n",
       " 524,\n",
       " 526,\n",
       " 529,\n",
       " 531,\n",
       " 532,\n",
       " 535,\n",
       " 537,\n",
       " 539,\n",
       " 541,\n",
       " 542,\n",
       " 545,\n",
       " 547,\n",
       " 548,\n",
       " 551,\n",
       " 552,\n",
       " 555,\n",
       " 556,\n",
       " 558,\n",
       " 560,\n",
       " 562,\n",
       " 565,\n",
       " 567,\n",
       " 569,\n",
       " 570,\n",
       " 573,\n",
       " 575,\n",
       " 577,\n",
       " 579,\n",
       " 580,\n",
       " 582,\n",
       " 585,\n",
       " 587,\n",
       " 588,\n",
       " 590,\n",
       " 592,\n",
       " 594,\n",
       " 596,\n",
       " 599,\n",
       " 600,\n",
       " 602,\n",
       " 604,\n",
       " 606,\n",
       " 609,\n",
       " 611,\n",
       " 613,\n",
       " 615,\n",
       " 616,\n",
       " 619,\n",
       " 620,\n",
       " 623,\n",
       " 625,\n",
       " 626,\n",
       " 628,\n",
       " 631,\n",
       " 632,\n",
       " 635,\n",
       " 636,\n",
       " 638,\n",
       " 641,\n",
       " 642,\n",
       " 645,\n",
       " 647,\n",
       " 648,\n",
       " 650,\n",
       " 652,\n",
       " 655,\n",
       " 656,\n",
       " 659,\n",
       " 660,\n",
       " 663,\n",
       " 665,\n",
       " 666,\n",
       " 669,\n",
       " 670,\n",
       " 673,\n",
       " 674,\n",
       " 677,\n",
       " 678,\n",
       " 681,\n",
       " 683,\n",
       " 685,\n",
       " 686,\n",
       " 689,\n",
       " 691,\n",
       " 692,\n",
       " 694,\n",
       " 696,\n",
       " 698,\n",
       " 701,\n",
       " 702,\n",
       " 705,\n",
       " 707,\n",
       " 709,\n",
       " 711,\n",
       " 713,\n",
       " 714,\n",
       " 717,\n",
       " 719,\n",
       " 720,\n",
       " 722,\n",
       " 725,\n",
       " 726,\n",
       " 728,\n",
       " 731,\n",
       " 732,\n",
       " 735,\n",
       " 737,\n",
       " 739,\n",
       " 741,\n",
       " 742,\n",
       " 745,\n",
       " 747,\n",
       " 749,\n",
       " 751,\n",
       " 752,\n",
       " 754,\n",
       " 756,\n",
       " 758,\n",
       " 761,\n",
       " 763,\n",
       " 764,\n",
       " 767,\n",
       " 768,\n",
       " 770,\n",
       " 773,\n",
       " 774,\n",
       " 777,\n",
       " 778,\n",
       " 780,\n",
       " 782,\n",
       " 784,\n",
       " 787,\n",
       " 788,\n",
       " 790,\n",
       " 793,\n",
       " 794,\n",
       " 797,\n",
       " 798,\n",
       " 800,\n",
       " 802,\n",
       " 804,\n",
       " 806,\n",
       " 809,\n",
       " 811,\n",
       " 813,\n",
       " 814,\n",
       " 817,\n",
       " 818,\n",
       " 821,\n",
       " 822,\n",
       " 824,\n",
       " 827,\n",
       " 828,\n",
       " 830,\n",
       " 832,\n",
       " 834,\n",
       " 836,\n",
       " 839,\n",
       " 840,\n",
       " 843,\n",
       " 845,\n",
       " 846,\n",
       " 848,\n",
       " 850,\n",
       " 852,\n",
       " 855,\n",
       " 856,\n",
       " 859,\n",
       " 860,\n",
       " 862,\n",
       " 865,\n",
       " 866,\n",
       " 868,\n",
       " 870,\n",
       " 873,\n",
       " 874,\n",
       " 876,\n",
       " 878,\n",
       " 880,\n",
       " 882,\n",
       " 884,\n",
       " 886,\n",
       " 888,\n",
       " 891,\n",
       " 892,\n",
       " 895,\n",
       " 896,\n",
       " 899,\n",
       " 900,\n",
       " 902,\n",
       " 904,\n",
       " 906,\n",
       " 908,\n",
       " 911,\n",
       " 913,\n",
       " 915,\n",
       " 916,\n",
       " 919,\n",
       " 920,\n",
       " 922,\n",
       " 924,\n",
       " 927,\n",
       " 929,\n",
       " 930,\n",
       " 932,\n",
       " 934,\n",
       " 937,\n",
       " 938,\n",
       " 940,\n",
       " 942,\n",
       " 944,\n",
       " 947,\n",
       " 948,\n",
       " 951,\n",
       " 953,\n",
       " 955,\n",
       " 957,\n",
       " 959,\n",
       " 960,\n",
       " 962,\n",
       " 965,\n",
       " 966,\n",
       " 968,\n",
       " 971,\n",
       " 972,\n",
       " 975,\n",
       " 976,\n",
       " 978,\n",
       " 981,\n",
       " 982,\n",
       " 984,\n",
       " 987,\n",
       " 989,\n",
       " 990,\n",
       " 993,\n",
       " 994,\n",
       " 996,\n",
       " 999,\n",
       " 1001,\n",
       " 1002,\n",
       " 1005,\n",
       " 1006,\n",
       " 1008,\n",
       " 1011,\n",
       " 1012,\n",
       " 1014,\n",
       " 1016,\n",
       " 1018,\n",
       " 1021,\n",
       " 1023]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0622558d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(est_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3e652f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(est_x[847]).intersection(s_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "42e5d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6426117097961406, 0.7304317044395013, 0.3563228120191924]\n",
      "[0.83789, 0.6749, 0.58815]\n"
     ]
    }
   ],
   "source": [
    "mi_range = [0.25, 1/16., 0.015625]\n",
    "posterior_success_rates = [calc_posterior(mi) for mi in mi_range]\n",
    "epsilon_vals = [dp_ps_to_epsilon(ps) for ps in posterior_success_rates]\n",
    "\n",
    "print(epsilon_vals)\n",
    "print([x for x in posterior_success_rates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8dac0bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "14\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# DP MEAN\n",
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_iris(normalize=True)\n",
    "true_mean = np.average(train_x, axis=0)\n",
    "\n",
    "dp_dists = {}\n",
    "num_trials = 1000\n",
    "for eps in epsilon_vals:\n",
    "    avg_dist_dp = {}\n",
    "    for i in range(1, 17):\n",
    "        clip_budget = i / 10\n",
    "        clipped_train_x = [clip_to_threshold(train_x[i], clip_budget) for i in range(len(train_x))]\n",
    "        released_mean = np.average(clipped_train_x, axis=0)\n",
    "        clip_dist = np.linalg.norm(released_mean - true_mean)\n",
    "        dist = 0.\n",
    "        sensitivity = clip_budget / train_len\n",
    "        for _ in range(num_trials):\n",
    "            released_mean = np.average(clipped_train_x, axis=0)\n",
    "            for ind in range(len(released_mean)):\n",
    "                sensitivity = clip_budget / train_len\n",
    "                released_mean[ind] += add_noise(sensitivity/eps)\n",
    "            dist += np.linalg.norm(released_mean - true_mean)\n",
    "        dist /= num_trials\n",
    "        avg_dist_dp[i] = (clip_dist, dist)\n",
    "    dp_key = min(avg_dist_dp.items(), key=lambda x: x[1][1])[0]\n",
    "    print(dp_key)\n",
    "    dp_dists[eps] = avg_dist_dp[dp_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1de7c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.6426117097961406: (0.003760138063449314, 0.02258502174391287),\n",
       " 0.7304317044395013: (0.01164606776365974, 0.04969819520789844),\n",
       " 0.3563228120191924: (0.02706865690970566, 0.09332670532636303)}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "b8332eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "25599033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00032252681632139\n",
      "0.0003155611516452299\n",
      "0.011478844241318502\n",
      "0.009559438148884583\n"
     ]
    }
   ],
   "source": [
    "with open(f'test/iris_mean_noise_ind=True.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "print(sum(noise.values()))   \n",
    "with open(f'data/iris_mean_noise_ind=True.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "print(sum(noise.values()))   \n",
    "\n",
    "with open(f'test/iris_mean_noise_ind=False.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "print(sum(noise.values()))   \n",
    "with open(f'data/iris_mean_noise_ind=False.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "print(sum(noise.values()))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "1429e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25: (0.04478935155240638, 0.044786037380054995, 0.043328539082840026), 0.0625: (0.045302130329422, 0.04532076107567905, 0.04433696289766765), 0.015625: (0.04465053429919298, 0.04493462221946383, 0.04446955524605017)}\n"
     ]
    }
   ],
   "source": [
    "# PAC MEAN LOCAL\n",
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_iris(normalize=True)\n",
    "true_mean = np.average(train_x, axis=0)\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "with open(f'test/iris_mean_noise_ind=True.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        choice = np.random.choice(range(1024))\n",
    "        shuffled_x1, shuffled_y1 = train_x[xs[choice]], train_y[xs[choice]]\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    subsampled_dist /= num_trials\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    \n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "\n",
    "#     subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)\n",
    "print(pac_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "622d5591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25: (0.04653742410836648, 0.04821759917638942, 0.04638160286888963), 0.0625: (0.04768789839040323, 0.06744404898300899, 0.07158395125256205), 0.015625: (0.046432717720573835, 0.1806701384927753, 0.2172688948316337)}\n"
     ]
    }
   ],
   "source": [
    "# PAC MEAN GLOBAL\n",
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_iris(normalize=True)\n",
    "true_mean = np.average(train_x, axis=0)\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "with open(f'test/iris_mean_noise_ind=False.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        choice = np.random.choice(range(1024))\n",
    "        shuffled_x1, shuffled_y1 = train_x[xs[choice]], train_y[xs[choice]]\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    subsampled_dist /= num_trials\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    \n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "\n",
    "#     subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)\n",
    "print(pac_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c7f2074e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.186335403726708"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.191/0.161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "559fd53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_bean(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "81d933e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0829053788327507\n"
     ]
    }
   ],
   "source": [
    "true_mean = np.average(train_x, axis=0)\n",
    "\n",
    "norms = [np.linalg.norm(x) for x in train_x]\n",
    "print(max(norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "5cb0127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1399897 , 0.22680687, 0.24606585, 0.23724242, 0.39587704,\n",
       "       0.76689908, 0.13704124, 0.22560331, 0.62619689, 0.9002929 ,\n",
       "       0.76622798, 0.46101523, 0.49242476, 0.37227223, 0.41488435,\n",
       "       0.91073302])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "1cc5c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP MEAN\n",
    "dp_dists = {}\n",
    "num_trials = 1000\n",
    "\n",
    "for eps in epsilon_vals:\n",
    "    avg_dist_dp = {}\n",
    "    for i in range(1, 31):\n",
    "        clip_budget = i/10\n",
    "        clipped_train_x = [clip_to_threshold(train_x[i], clip_budget) for i in range(len(train_x))]\n",
    "        released_mean = np.average(clipped_train_x, axis=0)\n",
    "        clip_dist = np.linalg.norm(released_mean - true_mean)\n",
    "        dist = 0.\n",
    "        for _ in range(num_trials):\n",
    "            released_mean = np.average(clipped_train_x, axis=0)\n",
    "            for ind in range(len(released_mean)):\n",
    "                sensitivity = clip_budget / train_len \n",
    "                released_mean[ind] += add_noise(sensitivity / eps)\n",
    "            dist += np.linalg.norm(released_mean - true_mean)\n",
    "        dist /= num_trials\n",
    "        avg_dist_dp[i] = (clip_dist, dist)\n",
    "    dp_key = min(avg_dist_dp.items(), key=lambda x: x[1][1])[0]\n",
    "    dp_dists[eps] = avg_dist_dp[dp_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "9188f447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.6426117097961406: (7.189599906288743e-05, 0.0010187629845155631),\n",
       " 0.7304317044395013: (0.00031403038825697635, 0.0022340125713306365),\n",
       " 0.3563228120191924: (0.0009807389338486732, 0.004459543287289186)}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "fbd34b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25: (0.0054849685943179766, 0.00548553984894541, 0.0053526367754119), 0.0625: (0.0054209992195542196, 0.005422277042560301, 0.005413025224079141), 0.015625: (0.005431260403192176, 0.005447635074952403, 0.00542849887481953)}\n"
     ]
    }
   ],
   "source": [
    "# PAC MEAN LOCAL\n",
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_bean(normalize=True)\n",
    "true_mean = np.average(train_x, axis=0)\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "with open(f'test/bean_mean_noise_ind=True.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        choice = np.random.choice(range(1024))\n",
    "        shuffled_x1, shuffled_y1 = train_x[xs[choice]], train_y[xs[choice]]\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    subsampled_dist /= num_trials\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    \n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "\n",
    "#     subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)\n",
    "print(pac_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "15fd8b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25: (0.005273732173374416, 0.005284740797201349, 0.005366049471830891), 0.0625: (0.005301985824324389, 0.005420389190747994, 0.005549304107713246), 0.015625: (0.00534384657254746, 0.006991745299157017, 0.008055822107875118)}\n"
     ]
    }
   ],
   "source": [
    "# PAC MEAN GLOBAL\n",
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_bean(normalize=True)\n",
    "true_mean = np.average(train_x, axis=0)\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "with open(f'test/bean_mean_noise_ind=False.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        choice = np.random.choice(range(1024))\n",
    "        shuffled_x1, shuffled_y1 = train_x[xs[choice]], train_y[xs[choice]]\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    subsampled_dist /= num_trials\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    \n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "\n",
    "#     subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)\n",
    "print(pac_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5ab9f416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.25: (0.005273732173374416, 0.005284740797201349, 0.005366049471830891),\n",
       " 0.0625: (0.005301985824324389, 0.005420389190747994, 0.005549304107713246),\n",
       " 0.015625: (0.00534384657254746, 0.006991745299157017, 0.008055822107875118)}"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "0426f57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.25: (0.005273732173374416, 0.005284740797201349, 0.005366049471830891),\n",
       " 0.0625: (0.005301985824324389, 0.005420389190747994, 0.005549304107713246),\n",
       " 0.015625: (0.00534384657254746, 0.006991745299157017, 0.008055822107875118)}"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "f95fbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7351afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_rice(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "963bb53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3296929410457268\n"
     ]
    }
   ],
   "source": [
    "true_mean = np.average(train_x, axis=0)\n",
    "\n",
    "norms = [np.linalg.norm(x) for x in train_x]\n",
    "print(max(norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "914db068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44901231, 0.50102237, 0.46286265, 0.55690775, 0.64194394,\n",
       "       0.45831109, 0.44831546])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d11e9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP MEAN\n",
    "dp_dists = {}\n",
    "num_trials = 1000\n",
    "\n",
    "for eps in epsilon_vals:\n",
    "    avg_dist_dp = {}\n",
    "    for i in range(1, 24):\n",
    "        clip_budget = i / 10\n",
    "        clipped_train_x = [clip_to_threshold(train_x[i], clip_budget) for i in range(len(train_x))]\n",
    "        released_mean = np.average(clipped_train_x, axis=0)\n",
    "        clip_dist = np.linalg.norm(released_mean - true_mean)\n",
    "        dist = 0.\n",
    "        for _ in range(num_trials):\n",
    "            released_mean = np.average(clipped_train_x, axis=0)\n",
    "            for ind in range(len(released_mean)):\n",
    "                sensitivity = clip_budget / train_len \n",
    "                released_mean[ind] += add_noise(sensitivity / eps)\n",
    "            dist += np.linalg.norm(released_mean - true_mean)\n",
    "        dist /= num_trials\n",
    "        avg_dist_dp[i] = (clip_dist, dist)\n",
    "    dp_key = min(avg_dist_dp.items(), key=lambda x: x[1][1])[0]\n",
    "    dp_dists[eps] = avg_dist_dp[dp_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f84fb3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.6426117097961406: (0.0003743330012744167, 0.0017075091220344863),\n",
       " 0.7304317044395013: (0.0003743330012744167, 0.0037607925542387103),\n",
       " 0.3563228120191924: (0.0014293079056475226, 0.007657317501067411)}"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d7e8af07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25: (0.007757612820548558, 0.007757542060921992, 0.007956547348488422), 0.0625: (0.007610703757303351, 0.007610691069106876, 0.007484078527585295), 0.015625: (0.008080336078943519, 0.008088101758080578, 0.0078917097872143)}\n"
     ]
    }
   ],
   "source": [
    "# PAC MEAN LOCAL\n",
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_rice(normalize=True)\n",
    "true_mean = np.average(train_x, axis=0)\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "with open(f'test/rice_mean_noise_ind=True.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        choice = np.random.choice(range(1024))\n",
    "        shuffled_x1, shuffled_y1 = train_x[xs[choice]], train_y[xs[choice]]\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    subsampled_dist /= num_trials\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    \n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "\n",
    "#     subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)\n",
    "print(pac_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9b4e652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25: (0.00748655011901608, 0.007504349828626526, 0.007806994039811815), 0.0625: (0.0075344489473279635, 0.007728619489802331, 0.0077494319984033125), 0.015625: (0.0074941816725075956, 0.009924254506241492, 0.011071368162478858)}\n"
     ]
    }
   ],
   "source": [
    "# PAC MEAN GLOBAL\n",
    "train_x, train_y, test_x, test_y, num_classes, train_len = gen_rice(normalize=True)\n",
    "true_mean = np.average(train_x, axis=0)\n",
    "subsample_rate = int(0.5*train_len)\n",
    "\n",
    "with open(f'test/rice_mean_noise_ind=False.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "\n",
    "\n",
    "pac_dists = {}\n",
    "num_trials = 1000\n",
    "for mi in mi_range:\n",
    "    scaled_noise = {k: noise[k] * (0.5 / mi) for k in noise}\n",
    "    iso_noise = max(scaled_noise.values())\n",
    "    iso_scaled = {k: iso_noise for k in noise}\n",
    "    avg_dist_pac = 0\n",
    "    avg_iso_dist_pac = 0\n",
    "    subsampled_dist = 0\n",
    "    for _ in range(num_trials):\n",
    "        choice = np.random.choice(range(1024))\n",
    "        shuffled_x1, shuffled_y1 = train_x[xs[choice]], train_y[xs[choice]]\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        subsampled_dist += np.linalg.norm(released_mean - true_mean)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=scaled_noise[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    subsampled_dist /= num_trials\n",
    "    for _ in range(num_trials):\n",
    "        shuffled_x1, shuffled_y1 = shuffle(train_x, train_y)\n",
    "        shuffled_x1, shuffled_y1 = get_samples_safe(shuffled_x1, shuffled_y1, num_classes, subsample_rate)\n",
    "        released_mean = np.average(shuffled_x1, axis=0)\n",
    "        for ind in range(len(released_mean)):\n",
    "            c = np.random.normal(0, scale=iso_scaled[ind])\n",
    "            released_mean[ind] += c\n",
    "        avg_iso_dist_pac += np.linalg.norm(released_mean - true_mean)\n",
    "    \n",
    "    avg_iso_dist_pac /= num_trials\n",
    "    avg_dist_pac /= num_trials\n",
    "\n",
    "#     subsampled_dist /= num_trials\n",
    "    pac_dists[mi] = (subsampled_dist, avg_dist_pac, avg_iso_dist_pac)\n",
    "print(pac_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c73c4799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.25: (0.00748655011901608, 0.007504349828626526, 0.007806994039811815),\n",
       " 0.0625: (0.0075344489473279635, 0.007728619489802331, 0.0077494319984033125),\n",
       " 0.015625: (0.0074941816725075956, 0.009924254506241492, 0.011071368162478858)}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "58675561",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'test/iris_mean_noise_ind=True.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "75762e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00032252681632139\n"
     ]
    }
   ],
   "source": [
    "print(sum(noise.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9e953387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003155611516452299\n"
     ]
    }
   ],
   "source": [
    "with open(f'mean_data/iris_mean_noise_ind=True.pkl', 'rb') as f:\n",
    "    noise, xs = pickle.load(f)[0.5] # keyed by MI, default is 0.5\n",
    "    \n",
    "print(sum(noise.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f165d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
